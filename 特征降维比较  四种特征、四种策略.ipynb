{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f37a2f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-21T09:22:42.230130Z",
     "start_time": "2023-04-21T09:22:42.225941Z"
    }
   },
   "outputs": [],
   "source": [
    "#二级结构特征、组成成分特征、位置特异性偏好特征、词向量编码\n",
    "#PCA降维、ICA降维、KPCA降维、LLE降维\n",
    "#这里的降维只是找出最好的降维策略，不是用来做最后的比较，不用在意性能变好了还是变差了"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1759c29",
   "metadata": {},
   "source": [
    "# 首先是二级结构特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e13e3ee1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-21T09:23:34.922057Z",
     "start_time": "2023-04-21T09:23:22.028800Z"
    }
   },
   "outputs": [],
   "source": [
    "from features import ensembleFeature\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import metricsCal\n",
    "from thundersvm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from features import ensembleFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "93b884e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-21T13:02:01.889280Z",
     "start_time": "2023-04-21T13:02:01.836106Z"
    }
   },
   "outputs": [],
   "source": [
    "def file_va(filename):\n",
    "    f = open(filename,\"rb\")\n",
    "    m=0\n",
    "    name = []\n",
    "    seq = []\n",
    "    struc = []\n",
    "    for i in f:\n",
    "        #print(i)\n",
    "        m+=1\n",
    "        if m>2 and (m-2)%3==1:\n",
    "            name.append(str(i[1:-1],'utf-8'))\n",
    "        if m>3 and (m-2)%3==2:\n",
    "            seq.append(str(i[:-1],'utf-8'))\n",
    "        if m>3 and (m-2)%3==0:\n",
    "            struc.append(str(i,'utf-8')[:41])\n",
    "    return name,seq,struc\n",
    "\n",
    "def RNAfold_dot(filename):\n",
    "    f = open(filename,\"rb\")\n",
    "    m = 0\n",
    "    struc = []\n",
    "    seq = []\n",
    "    for i in f:\n",
    "        m+=1\n",
    "        if m%6==3:\n",
    "            struc.append(str(i[0:41],'utf-8'))\n",
    "        if m%6==2:\n",
    "            seq.append(str(i[0:41],'utf-8'))\n",
    "    return seq,struc\n",
    "\n",
    "def struc_01(data):\n",
    "    x = np.zeros(len(data)*2).reshape(-1,2)\n",
    "    for i in range(len(data)):\n",
    "        if data[i]==\"(\":\n",
    "            x[i][0]=1\n",
    "        elif data[i]==\")\":\n",
    "            x[i][1]=1\n",
    "    return x\n",
    "\n",
    "def struc_01_8(data):\n",
    "    x = np.zeros((len(data)-2)*8).reshape(-1,8)\n",
    "    for i in range(len(data)-2):\n",
    "        mm = 0\n",
    "        if data[i]==\"(\" or data[i]==\")\":\n",
    "            mm+=4\n",
    "        if data[i+1]==\"(\" or data[i]==\")\":\n",
    "            mm+=2\n",
    "        if data[i+2]==\"(\" or data[i]==\")\":\n",
    "            mm+=1\n",
    "        x[i][mm]=1\n",
    "    return x\n",
    "\n",
    "##将序列转化为词向量用到的函数\n",
    "def fa_seq(filepath):\n",
    "    f = open(filepath,'r')\n",
    "    x = []\n",
    "    for i in f:\n",
    "        x.append(i)\n",
    "    seq = []\n",
    "    for i in range(len(x)):\n",
    "        if i%2==1:\n",
    "            seq.append(x[i][:-1])\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c21dcfc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-21T09:23:43.952913Z",
     "start_time": "2023-04-21T09:23:41.116075Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_name,train_seq,train_struc = file_va(\"data/mouse_train.log\")\n",
    "trainPosLabel = np.ones(int(len(train_seq)/2))\n",
    "trainNegLabel = np.zeros(int(len(train_seq)/2))\n",
    "trainLabel = np.append(trainPosLabel,trainNegLabel)\n",
    "#获取01二级结构表示\n",
    "trainData = []\n",
    "for i in range(len(train_struc)):\n",
    "    trainData.append(struc_01(train_struc[i]))\n",
    "trainData = np.array(trainData)\n",
    "        \n",
    "#与单热编码结合\n",
    "trainData_origin = np.append(trainData,ensembleFeature.Binary(train_seq),axis=2).reshape(trainData.shape[0],-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c463e414",
   "metadata": {},
   "source": [
    "# 词向量嵌入特征，MultiLabel的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "669d21a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T04:32:26.695182Z",
     "start_time": "2023-05-29T04:32:26.675341Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import math\n",
    "from utils import metricsCal\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from thundersvm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from Model import MultiLabel_fine_tuning as Model\n",
    "import os\n",
    "##将序列转化为词向量用到的函数\n",
    "def fa_seq(filepath):\n",
    "    f = open(filepath,'r')\n",
    "    x = []\n",
    "    for i in f:\n",
    "        x.append(i)\n",
    "    seq = []\n",
    "    for i in range(len(x)):\n",
    "        if i%2==1:\n",
    "            seq.append(x[i][:-1])\n",
    "    return seq\n",
    "\n",
    "class EmbeddingSeq(nn.Module):\n",
    "    def __init__(self,weight_dict_path):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            weight_dict_path: path of pre-trained embeddings of RNA/dictionary\n",
    "        \"\"\"\n",
    "        super(EmbeddingSeq,self).__init__()\n",
    "        weight_dict = pickle.load(open(weight_dict_path,'rb'))\n",
    "\n",
    "        weights = torch.FloatTensor(list(weight_dict.values())).cuda()\n",
    "        num_embeddings = len(list(weight_dict.keys()))\n",
    "        embedding_dim = 300\n",
    "\n",
    "        self.embedding = nn.Embedding(num_embeddings=num_embeddings,embedding_dim=embedding_dim)\n",
    "        self.embedding.weight = nn.Parameter(weights)\n",
    "        self.embedding.weight.requires_grad = False\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        out = self.embedding(x.type(torch.cuda.LongTensor))\n",
    "\n",
    "        return out\n",
    "\n",
    "def seq2index(seqs,my_dict,window=3,save_data=False):\n",
    "    \"\"\"\n",
    "    Convert single RNA sequences to k-mers representation.\n",
    "        Inputs: ['ACAUG','CAACC',...] of equal length RNA seqs\n",
    "        Example: 'ACAUG' ----> [ACA,CAU,AUG] ---->[21,34,31]\n",
    "    \"\"\"\n",
    "\n",
    "    num_samples = len(seqs)\n",
    "    temp = []\n",
    "    for k in range(num_samples):\n",
    "        length = len(seqs[k])\n",
    "        seqs_kmers = [seqs[k][i:i+window] for i in range(0,length-window+1)]\n",
    "        temp.append(seqs_kmers)\n",
    "\n",
    "\n",
    "    seq_kmers = pd.DataFrame(data = np.concatenate(temp,axis=0))\n",
    "\n",
    "    # load pretained word2vec embeddings\n",
    "\n",
    "    word2index = word2index_(my_dict)\n",
    "\n",
    "    seq_kmers_index = seq_kmers.applymap(lambda x: mapfun(x,my_dict))\n",
    "\n",
    "\n",
    "    return seq_kmers_index.to_numpy()\n",
    "def word2index_(my_dict):\n",
    "    word2index = dict()\n",
    "    for index, ele in enumerate(list(my_dict.keys())):\n",
    "        word2index[ele] = index\n",
    "\n",
    "    return word2index\n",
    "\n",
    "def mapfun(x,my_dict):\n",
    "    if x not in list(my_dict.keys()):\n",
    "        return None\n",
    "    else:\n",
    "        return word2index_(my_dict)[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b646e73d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T04:32:34.310063Z",
     "start_time": "2023-05-29T04:32:28.804530Z"
    }
   },
   "outputs": [],
   "source": [
    "##得到train Label，trainData维度是1*39*300\n",
    "embed = EmbeddingSeq('features/embeddings_12RM.pkl')\n",
    "embeddings_dict = pickle.load(open('features/embeddings_12RM.pkl','rb'))\n",
    "train_seq = fa_seq(\"data/Mouse/mouse_train.fasta\")\n",
    "trainLabel = np.append(np.ones(int(len(train_seq)/2)),np.zeros(int(len(train_seq)-len(train_seq)/2)),axis=0)\n",
    "seq_T = []\n",
    "for i in train_seq:\n",
    "    seq_T.append(i.replace('U','T'))\n",
    "x = seq2index(seq_T,embeddings_dict)\n",
    "seqs_kmers_index = torch.transpose(torch.from_numpy(x),0,1)\n",
    "trainData_origin = np.array(embed(seqs_kmers_index).view(len(train_seq),1,-1,300).cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a787e6c",
   "metadata": {},
   "source": [
    "# 组成成分特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "025ab726",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-21T12:31:48.581770Z",
     "start_time": "2023-04-21T12:23:54.485097Z"
    }
   },
   "outputs": [],
   "source": [
    "trainData_EIIP = ensembleFeature.EIIP(train_seq)\n",
    "\n",
    "trainData_PseEIIP = ensembleFeature.PseEIIP(train_seq)\n",
    "\n",
    "trainData_PCP = ensembleFeature.PCP(train_seq)\n",
    "\n",
    "trainData_NCPA = ensembleFeature.NCPA(train_seq)\n",
    "trainData_NCPA = trainData_NCPA.reshape(trainData_NCPA.shape[0],-1)\n",
    "\n",
    "trainData_DBPF = ensembleFeature.DBPF(train_seq)\n",
    "trainData_DBPF = trainData_DBPF.reshape(trainData_DBPF.shape[0],-1)\n",
    "\n",
    "trainData_origin = np.concatenate(  (trainData_EIIP,trainData_PseEIIP,trainData_PCP,trainData_NCPA,trainData_DBPF),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718348a5",
   "metadata": {},
   "source": [
    "# 位置特异性偏好特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "55da92a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T12:35:59.617639Z",
     "start_time": "2023-05-12T12:35:42.284387Z"
    }
   },
   "outputs": [],
   "source": [
    "train_seq = fa_seq(\"data/Mouse/mouse_train.fasta\")\n",
    "test_seq = fa_seq(\"data/Mouse/mouse_indep.fasta\")\n",
    "trainPos_seq = train_seq[0:int(len(train_seq)/2)]\n",
    "trainNeg_seq = train_seq[int(len(train_seq)/2):]\n",
    "testPos_seq = test_seq[0:int(len(test_seq)/2)]\n",
    "testNeg_seq = test_seq[int(len(test_seq)/2):]\n",
    "trainLabel = np.append(np.ones(int(len(train_seq)/2)),np.zeros(int(len(train_seq)-len(train_seq)/2)),axis=0)\n",
    "testLabel = np.append(np.ones(int(len(test_seq)/2)),np.zeros(int(len(test_seq)-len(test_seq)/2)),axis=0)\n",
    "\n",
    "#首先把所有特征表示出来\n",
    "#值\n",
    "trainPos,trainNeg,testPos,testNeg = ensembleFeature.PSKP(trainPos_seq,trainNeg_seq,testPos_seq,testNeg_seq,1) #3代表PSTP，2代表PSDP，1代表PSNP\n",
    "trainData_PSNP = np.vstack((trainPos,trainNeg))\n",
    "testData_PSNP = np.vstack((testPos,testNeg))\n",
    "trainPos,trainNeg,testPos,testNeg = ensembleFeature.PSKP(trainPos_seq,trainNeg_seq,testPos_seq,testNeg_seq,2) #3代表PSTP，2代表PSDP，1代表PSNP\n",
    "trainData_PSDP = np.vstack((trainPos,trainNeg))\n",
    "testData_PSDP = np.vstack((testPos,testNeg))\n",
    "trainPos,trainNeg,testPos,testNeg = ensembleFeature.PSKP(trainPos_seq,trainNeg_seq,testPos_seq,testNeg_seq,3) #3代表PSTP，2代表PSDP，1代表PSNP\n",
    "trainData_PSTP = np.vstack((trainPos,trainNeg))\n",
    "testData_PSTP = np.vstack((testPos,testNeg))\n",
    "trainData_PSKP = np.hstack((trainData_PSNP,trainData_PSDP,trainData_PSTP))\n",
    "testData_PSKP = np.hstack((testData_PSNP,testData_PSDP,testData_PSTP))\n",
    "\n",
    "\n",
    "\n",
    "trainPos,trainNeg,testPos,testNeg = ensembleFeature.PSCP(trainPos_seq,trainNeg_seq,testPos_seq,testNeg_seq,0)\n",
    "trainData_PSCP_0 = np.vstack((trainPos,trainNeg))\n",
    "testData_PSCP_0 = np.vstack((testPos,testNeg))\n",
    "trainPos,trainNeg,testPos,testNeg = ensembleFeature.PSCP(trainPos_seq,trainNeg_seq,testPos_seq,testNeg_seq,1)\n",
    "trainData_PSCP_1 = np.vstack((trainPos,trainNeg))\n",
    "testData_PSCP_1 = np.vstack((testPos,testNeg))\n",
    "trainPos,trainNeg,testPos,testNeg = ensembleFeature.PSCP(trainPos_seq,trainNeg_seq,testPos_seq,testNeg_seq,2)\n",
    "trainData_PSCP_2 = np.vstack((trainPos,trainNeg))\n",
    "testData_PSCP_2 = np.vstack((testPos,testNeg))\n",
    "\n",
    "trainData_PSCP = np.hstack((trainData_PSCP_0,trainData_PSCP_1,trainData_PSCP_2))\n",
    "testData_PSCP = np.hstack((testData_PSCP_0,testData_PSCP_1,testData_PSCP_2))\n",
    "\n",
    "trainPos,trainNeg,testPos,testNeg = ensembleFeature.BPB(trainPos_seq,trainNeg_seq,testPos_seq,testNeg_seq)\n",
    "trainData_BPB = np.vstack((trainPos,trainNeg))\n",
    "testData_BPB = np.vstack((testPos,testNeg))\n",
    "\n",
    "trainData_KNN = np.array(pd.read_csv(\"features/KNN_value_train.csv\").iloc[:,1:])\n",
    "testData_KNN = np.array(pd.read_csv(\"features/KNN_value_test.csv\").iloc[:,1:])\n",
    "\n",
    "trainData_origin = np.hstack((trainData_PSKP,trainData_PSCP,trainData_BPB))#,trainData_KNN))\n",
    "testData = np.hstack((testData_PSKP,testData_PSCP,testData_BPB))#,testData_KNN))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d080cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-21T13:04:02.715972Z",
     "start_time": "2023-04-21T13:04:02.699351Z"
    }
   },
   "source": [
    "# 下面是降维四件套"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19139973",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T04:55:58.394226Z",
     "start_time": "2023-05-29T04:55:58.389768Z"
    }
   },
   "outputs": [],
   "source": [
    "trainData = trainData_origin.reshape(9126,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23c915ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T04:56:27.698511Z",
     "start_time": "2023-05-29T04:56:27.694456Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9126, 800)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0433713",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T04:56:27.072997Z",
     "start_time": "2023-05-29T04:55:59.760697Z"
    }
   },
   "outputs": [],
   "source": [
    "#主成分分析降维  sec_PCA  com_PCA loc_PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=800)  # 加载PCA算法，设置降维后主成分数目为2\n",
    "pca.fit(trainData)  # 对样本进行降维\n",
    "trainData = pca.transform(trainData)\n",
    "#testdata_x = pca.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e5bc9ad7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T12:37:40.290797Z",
     "start_time": "2023-05-12T12:36:01.063430Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/xiayunpeng/anaconda3/envs/BERT/lib/python3.6/site-packages/sklearn/decomposition/_fastica.py:120: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#ICA降维  sec_ICA  com_ICA loc_ICA\n",
    "from sklearn.decomposition import FastICA\n",
    "ica = FastICA(n_components= 100).fit(trainData_origin)\n",
    "trainData = ica.transform(trainData_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e4a15a41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-21T13:18:40.560655Z",
     "start_time": "2023-04-21T13:13:32.798240Z"
    }
   },
   "outputs": [],
   "source": [
    "#KPCA降维  sec_KPCA  com_KPCA loc_KPCA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "scikit_kpca = KernelPCA(n_components=100, kernel='linear', gamma=3)\n",
    "scikit_kpca.fit(trainData_origin)\n",
    "trainData = scikit_kpca.transform(trainData_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b762f2e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-21T13:25:13.847770Z",
     "start_time": "2023-04-21T13:19:12.941923Z"
    }
   },
   "outputs": [],
   "source": [
    "#LLE降维  sec_LLE  com_LLE loc_LLE\n",
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "lle = LocallyLinearEmbedding(n_components=100, n_neighbors=50, random_state=42)\n",
    "lle.fit(trainData_origin)\n",
    "trainData = lle.transform(trainData_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eab566a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T04:56:56.386012Z",
     "start_time": "2023-05-29T04:56:28.273185Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/xiayunpeng/anaconda3/envs/BERT/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass shuffle=True, random_state=10 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7977145881447267\n",
      "0.8014374741936412\n",
      "0.8176311343214807\n",
      "0.7987520998320135\n",
      "0.8181006423366074\n",
      "0.8090493018944442\n",
      "0.7870923598797317\n",
      "0.8218048909514992\n",
      "0.798684185214397\n",
      "0.8113396358038054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8061606312572348"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#交叉验证\n",
    "rows = 10\n",
    "row = -1\n",
    "row_name = []\n",
    "Sen = np.zeros(rows)\n",
    "Spe = np.zeros(rows)\n",
    "Acc = np.zeros(rows)\n",
    "Mcc = np.zeros(rows)\n",
    "Auc = np.zeros(rows)\n",
    "\n",
    "kf = KFold(10,True,10)\n",
    "for i,[train_index, test_index] in enumerate(kf.split(trainData)):\n",
    "    row+=1\n",
    "    row_one = \"Bert6mA_origin_KFold_\" + str(i)\n",
    "    row_name.append(row_one)\n",
    "    X_train = trainData[train_index]\n",
    "    X_test = trainData[test_index]\n",
    "    Y_train = trainLabel[train_index]\n",
    "    Y_test = trainLabel[test_index]\n",
    "    \n",
    "    model = SVC(C=1.0,gamma=\"auto\")\n",
    "    \n",
    "#     ica = FastICA(n_components= 100)\n",
    "#     ica.fit(X_train)\n",
    "#     X_train = ica.transform(X_train)\n",
    "#     X_test = ica.transform(X_test)\n",
    "    \n",
    "    model.fit(X_train,Y_train)\n",
    "    th,_,_,_,_,_,_,_,_,_ = metricsCal.get_train_metrics( model.decision_function(X_train).reshape(-1), Y_train )\n",
    "    _,_,_,_,sen,spe,acc,mcc,auc = metricsCal.get_test_metrics( model.decision_function(X_test), Y_test,th )\n",
    "    Sen[row] = sen\n",
    "    Spe[row] = spe\n",
    "    Acc[row] = acc\n",
    "    Mcc[row] = mcc\n",
    "    Auc[row] = auc\n",
    "#     _,_,_,_,sen,spe,acc,mcc,auc = metricsCal.get_test_metrics( model.decision_function(testdata_x), testLabel,th )\n",
    "    print(auc)\n",
    "wv_PCA = np.vstack((Sen,Spe,Acc,Mcc,Auc))\n",
    "np.mean(wv_PCA[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cef7bde6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-21T14:01:22.429202Z",
     "start_time": "2023-04-21T14:01:22.421220Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7875    , 0.7690583 , 0.8125    , 0.81777778, 0.77896996,\n",
       "        0.79097387, 0.77521008, 0.79120879, 0.74454148, 0.81431767],\n",
       "       [0.69515012, 0.70877944, 0.67483296, 0.66954644, 0.74049217,\n",
       "        0.68902439, 0.67889908, 0.69584245, 0.70704846, 0.63225806],\n",
       "       [0.74370208, 0.73822563, 0.74479737, 0.74260679, 0.76013143,\n",
       "        0.73603505, 0.72916667, 0.74342105, 0.72587719, 0.72149123],\n",
       "       [0.48535485, 0.47829264, 0.49252105, 0.49221274, 0.51998161,\n",
       "        0.47954701, 0.4567679 , 0.48923008, 0.45193783, 0.45334392],\n",
       "       [0.81109988, 0.81508244, 0.82542143, 0.81600672, 0.83039529,\n",
       "        0.82267346, 0.79500424, 0.82671027, 0.80282977, 0.81378365]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sec_PCA  com_PCA loc_PCA\n",
    "sec_ICA  com_ICA loc_ICA\n",
    "sec_KPCA  com_KPCA loc_KPCA\n",
    "sec_LLE  com_LLE loc_LLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a53c02bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-21T14:14:31.350318Z",
     "start_time": "2023-04-21T14:14:31.339406Z"
    }
   },
   "outputs": [],
   "source": [
    "a = np.vstack( (np.mean(sec_PCA,axis=1),np.mean(sec_ICA,axis=1),np.mean(sec_KPCA,axis=1),np.mean(sec_LLE,axis=1),\n",
    "np.mean(com_PCA,axis=1),np.mean(com_ICA,axis=1),np.mean(com_KPCA,axis=1),np.mean(com_LLE,axis=1),\n",
    "np.mean(loc_PCA,axis=1),np.mean(loc_ICA,axis=1),np.mean(loc_KPCA,axis=1),np.mean(loc_LLE,axis=1)))\n",
    "\n",
    "lista = [\"sec_PCA\",\"sec_ICA\",\"sec_KPCA\",\"sec_LLE\",\"com_PCA\",\"com_ICA\",\"com_KPCA\",\"com_LLE\",\"loc_PCA\",\"loc_ICA\",\"loc_KPCA\",\"loc_LLE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c7a90550",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-21T14:16:49.428182Z",
     "start_time": "2023-04-21T14:16:49.223169Z"
    }
   },
   "outputs": [],
   "source": [
    "#pd.DataFrame(np.append(np.array(lista).reshape(-1,1),a,axis=1)).to_csv(\"Result/sec_com_loc_reduce_dimension.csv\",header=[\"name\",\"Sen\",\"Spe\",\"Acc\",\"Mcc\",\"Auc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "04f523bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:32:44.650623Z",
     "start_time": "2023-05-16T14:32:44.643562Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.70347623, 0.70605237, 0.7111661 , 0.70309575, 0.69704804,\n",
       "       0.72033051, 0.68024584, 0.68387477, 0.70729373, 0.69531645])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d82c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:BERT]",
   "language": "python",
   "name": "conda-env-BERT-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
